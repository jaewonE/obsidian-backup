1 답변
귀무가설: TV, radio, newspaper 광고는 판매량에 영향을 주지 않는다.
대립가설: TV, radio, newspaper 광고는 판매량에 영향을 준다.

newspaper의 p-값은 큼으로 newspaper 광고는 판매량에 영향을 주지 않는다. 
반대로 TV와 radio 광고는 판매량에 유의미한 영향을 준다. 

2 답변
KNN 분류기: [[KNN K-최근접이웃]]
KNN 회귀분석 : KNN을 이용한 회귀 분석(알아보기)

3 답변
문제에 근거하여 아래와 같이 식을 작성 할 수 있다.
$$y_i = 50 + 20X_1 + 0.07X_2 + 35X_3 + 0.01X_1X_2 -10X_1X_3 +\epsilon$$
$$y_i\begin{cases}\,\,85 + (10+0.01X_2)X_1 + 0.07X_2 +\epsilon & \text { i 번째 사람이 여성인 경우 } \\\\ \,\,50 + (20+ 0.01X_2)X_1 + 0.07X_2 +\epsilon & \text{ i 번째 사람이 남성인 경우}\end{cases}$$
a번
i. $X_1$ 과 $X_2$의 값이 고정임으로 상호작용항인 $x_4$ 또한 고정이다. 여성일 경우 1임으로 예 y의 값이 남성일 경우보다 크다. 따라서 남성이 여성보다 평균적으로 수입이 더 적다(?)
> #질문 
> 그렇다면 남성이 1 이고 여성이 0으로 설정하면 값이 뒤바뀌는 것인가? 아무래도 $X_5$에 따른 값이 변화를 물어보는 것 같은데 어떻게 $X_5$값을 도출 할 수 있는지 의문.
![[KakaoTalk_Photo_2023-02-28-14-40-07.jpeg]]
ii: i번의 반대 질문임으로 참.
iii: 위와 마찬가지의 논리로 여성일 경우 1임으로, GPA와 성별의 상호작용항인 $X_5$값이 여성일 경우 더 크다. 이때 $X_5$의 계수($\beta_5$)는 음수임으로 $X_5$의 값이 커질수록 예측된 y값이 작아짐으로 참이다.
iiii: iii와 반대 질문임으로 거짓.

b번
IQ가 110이고 GPA가 4.0임으로 식은 아래와 같이 다시 작성할 수 있다.
$$y_i = 137.7 + 35X_3 + 0.01X_4 -10X_5 +\epsilon$$
$$y_i\begin{cases}\,\,137.1 +\epsilon & \text { i 번째 사람이 여성인 경우 } \\\\ \,\,142.1 +\epsilon & \text{ i 번째 사람이 남성인 경우}\end{cases}$$


4번
(a). 다중선형회귀의 RSS가 더 작다. 더 많이 적합



7번
Chapter 3, Problem 7
========================================================

Generic Solution
--------------------------------------------------------

**Proposition**: Prove that in case of simple linear regression:

$$ y = \beta_0 + \beta_1 x + \varepsilon $$

the $R^2$ is equal to correlation between X and Y squared, e.g.:

$$ R^2 = corr^2(x, y) $$

We'll be using the following definitions to prove the above proposition.

**Def**:
$$ R^2 = \frac{TSS - RSS}{TSS} $$

**Def**:
$$ TSS = \sum (y_i - \bar{y})^2 \label{TSS} $$

**Def**:
$$ RSS = \sum (y_i - \hat{y}_i)^2 \label{RSS} $$ 

**Def**:
$$
\begin{align}
  corr(x, y) &= \frac{\sum (x_i - \bar{x}) (y_i - \bar{y})}
                     {\sigma_x \sigma_y} \\
  \sigma_x^2 &= \sum (x_i - \bar{x})^2 \\
  \sigma_y^2 &= \sum (y_i - \bar{y})^2
\end{align}
$$

**Proof**:

Substitute defintions of TSS and RSS into $R^2$:

$$
R^2 = \frac{\sum (y_i - \bar{y})^2 - \sum (y_i - \hat{y}_i)^2}
           {\sum (y_i - \bar{y})^2}
$$

Let's work on the numerator:

$$
\begin{align}
  A &= \sum (y_i - \bar{y})^2 - \sum (y_i - \hat{y}_i)^2 \\
    &= \sum \left[ (y_i - \bar{y}) - (y_i - \hat{y}_i) \right] 
            \left[ (y_i - \bar{y}) + (y_i - \hat{y}_i) \right] \\
    &= \sum (\hat{y}_i - \bar{y})
            (2y_i - \bar{y} - \hat{y}_i)
\end{align}
$$

Recall that:

$$
\begin{align}
  \hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \label{beta0} \\
  \hat{\beta}_1 &= \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}
                        {\sum (x_j - \bar{x})^2}
\end{align}
$$

Substitute the expression for $\hat{\beta}_0$ into $\hat{y}_i$:

$$
\begin{align}
  \hat{y}_i &= \hat{\beta}_0 + \hat{\beta}_1 x_i \\
            &= \bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 x_i \\
            &= \bar{y} + \hat{\beta}_1 (x_i - \bar{x})
\end{align}
$$

Let's analyze two terms from $A$:

$$
\begin{align}
         \hat{y}_i - \bar{y} &= \hat{\beta}_1 (x_i - \bar{x}) \\
  2y_i - \bar{y} - \hat{y}_i &= 2y_i - \bar{y} - \bar{y} -
                                \hat{\beta}_1 (x_i - \bar{x}) \\
                             &= 2(y_i - \bar{y}) - 
                                \hat{\beta}_1 (x_i - \bar{x}) 
\end{align}
$$

and substitute these expressions back into $A$:

$$
\begin{align}
  A &= \sum \hat{\beta}_1 (x_i - \hat{x})
            \left[ 2(y_i - \bar{y}) - \hat{\beta}_1 (x_i - \bar{x}) \right] \\
    &= \hat{\beta}_1 \sum (x_i - \bar{x})
                          \left[ 2(y_i - \bar{y}) -
                                 \hat{\beta}_1 (x_i - \bar{x}) \right] \\
    &= \hat{\beta}_1
       \left[ 2 \sum (x_i - \bar{x})(y_i - \bar{y}) -
              \hat{\beta}_1 \sum (x_i - \bar{x})^2 \label{A4} \right]
\end{align}
$$

Using formula for $\hat{\beta}_1$ it is easy to see that the last term is
nothing but:

$$ \sum (x_i - \bar{x}) (y_i - \bar{y}) $$

Thus, we get:

$$
\begin{align}
  A &= \hat{\beta}_1 \sum (x_i - \bar{x}) (y_i - \bar{y}) \\
    &= \frac{\left[ \sum (x_i - \bar{x}) (y_i - \bar{y}) \right]^2}
            {\sum (x_j - \bar{x})^2}
\end{align}
$$

Plug the final expression for $A$ back into $R^2$:

$$
R^2 = \frac{\left[ \sum (x_i - \bar{x}) (y_i - \bar{y}) \right]^2}
           {\sum (x_j - \bar{x})^2 \sum (y_k - \bar{y})^2}
$$

Compare this to the definition of correlation and get:

$$ R^2 = corr^2(x, y) $$

8번 (Auto data set을 사용하라)

a
```
#ISLR 패키지를 불러온다
library(ISLR)

#Auto 데이터셋을 불러온다
data(Auto)

#lm()함수를 사용해서 mpg(연비)와 horsepower(마력) 사이의 선형회귀 모델을 만들고, data 매개변수를 사용하여 Auto 데이터셋을 지정하여, 모델을 mpg_power에 저장한다.
mpg_power <- lm(mpg~horsepower, data=Auto)

#summary()함수를 사용하여 mpg_power 모델에 대한 요약 통계를 출력한다.
summary(mpg_power)
```
출력
![[Pasted image 20230302130629.png]]
1. Call: 모델의 호출 정보
	* lm() 함수의 formula 매개변수와 data 매개변수를 사용하여 모델이 생성되었다.
2. Residuals: 모델에서 예측한 값과 실제 값 사이의 [[잔차(residual)]] -> 모델의 적합도 평가 가능
	* 각 항목의 의미
		- Min: 최소 잔차
		- 1Q: 제 1 사분위수
		- Median: 중앙값
		- 3Q: 제 3 사분위수
		- Max: 최대 잔차
	* 모델의 적합도 평가
		- ![[잔차(residual)]]
