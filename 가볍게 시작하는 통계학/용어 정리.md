MLE란?

- 모수적인 데이터 밀도 추정 방법

```
데이터가 주어지고
특정 분포를 가정했을 때, (확률 밀도 함수를 모르는데 알고자 함 )
특정 분포의 모수(관심있는 통계치 : 평균, 분산 등)를 추정한다.
```

likelihood 가능도(기여도)

```
데이터별로 임의의 파라미터(모수)의 분포에 해당하는 확률분포의 높이(확률)을 기여도라고 함
이러한 높이를 다 곱한게 기여도

우측 분포에선 빨간색 분포일때 높이의 곱이 가장 클 것이다. (그림 생략)
이러한 기여도의 최대값을 찾기 위해서 (로그값의) 미분(편미분) 한다.
```

Proba vs likelihood

```
확률(Probability) :
어떤 시행(trial, experiment)에서 특정 결과(sample)가 나올 가능성.
즉, 시행 전 모든 경우의 수의 가능성은 정해져 있으며 그 총합은 1(100%)이다.

가능도(Likelihood) : 어떤 시행(trial, experiment)을 충분히 수행한 뒤
그 결과(sample)를 토대로 경우의 수의 가능성을 도출하는 것.
아무리 충분히 수행해도 어디까지나 추론(inference)이기 때문에 가능성의 합이 1이 되지 않을 수도 있다.
```

검정통계량이란?

```
통계적 가설의 진위여부를 검정하기위해
“표본으로부터 계산”하는 통계량 ( 표본 통계량을 2차 가공한 것 )
```

그럼 검정통계량에는 무엇이 았나?

```
t 분포 => 카이스퀘어 검정 => F 검정
```

t-분포에서 t-value란?

```
T-value 의 의미 :
두 표본 집단의 차이를 비교. 주로 표본 평균의 차이를 비교하기 위한 검정통계량으로 사용함
그룹 1과 그룹2 간의 평균값을 비교

평균값의 차이를 계산하면서, 동시에 표본 그룹의 평균값들은 오차를 수반한다는 사실을 염두하여
( 표본 평균은 추정치이기 때문에 오차를 갖고 있고 불확실성을 가지고 있음 )
불확실도를 나누어줌

따라서 전체적인 식은 ( (평균의) 차이 ) / 불확실도 의 형태임
```

충분히 큰 t-value 는 어떻게 정해지는가?

```
어떠한 t_기준을 정하여 이 값보다 크다면 t_value가 충분히 커서 차이가 난다. 라고 말함
보통 상위 2.5% 하위 2.5% 와 같은 기준을 내림
t_분포 상에서 적절한 기준을 정하여 크다/작다를 결정한다
```

카이 제곱이란?

```
양의 정수 k에 대해, k개의 독립적이고 표준정규분포를 따르는 확률변수 x1 ~ xk 를 정의하면
카이제곱 분포는 sigma( xi ^2 ) 의 분포이다.
```

그러면 이런 이상한 검정통계량은 왜 쓰는걸까?

```
검정 통계량의 예시중 하나로써 카이스퀘어가
존재하고, 검정 통계량은 통계적 가설 진위여부를 판단하기 위해
사용한다고 했었다.

카이제곱 분포는 오차 혹은 편차를 분석할 때 도움된다.
```

오차나 편차를 왜 분석하는가?

```
(회귀) 모델링에서 오차를 정규분포로 가정하여 모델링한다.
우측의 실제값과 예측값의 차이가 표준정규분포에서 나왔을 것이라고 예측하며 모델링한다.
이런 경우 카이제곱 분포를 활용하면 이 오차가 유의하게 큰지 검증 가능

또, CLT에 따르면 샘플 수가 무수히 많고 합을 이용해 오차를
정의하면 그 오차의 분포는 정규분포이다.
( MSE 의 분포는 정규 분포를 따름 )

따라서 카이제곱 분포를 이용해 오차를 검증하면
오차가 우연히 발생한 것인지, 숨겨진 의미가 있는 오차인 것인지(모델이 잘못 예측) 판단할 수 있다.
```

피어슨 카이제곱 통계량이란?

```
피처슨 카이제곱 통계량 식을 보면
(앞서 살펴봤던) sigma( x^2 ) 의 형태랑은 다름.

피어슨 카이제곱 통계량에선
sigma ( 관측 빈도 - 기대 빈도 )^2 / (기대빈도) 의 형태
rough 하게, 오차의 제곱 합을 기대 빈도로 나눠줘서 정규화해준 형태

그런데 왜 기대빈도로 나누나?
그 이유는 표준편차로 나누지 못해서 ( 이유는 교과서의 범위를 벗어남 )
기대값으로 나눠주고, 그 결과 자유도가 1개 낮은 카이제곱 분포를 따른다.
```

카이제곱 검정이란?

```
카이제곱 검정은 크게 2가지의 경우에서 사용된다.
1. 적합도 검정 : 독립 변수가 하나일 때, 기대 빈도 분포와 실제 빈도 분포의 차이를 비교
2. 교차 분석 : 범주형 변수가 여러개일때 ( 변수가 2개 혹은 2개 이상 )
범주간 실제 빈도와 기대 빈도간 차이가 유의하게 있는지 판단
```

F 분포에서 F-value란?

```
여러 표본 집단을 비교해야 할 때가 있음 ( 주로 표본 평균을 비교하고자 함 )

우측 그림(생략)을 보면 음식 A를 먹은 사람의 평균이 좀 낮아 보이긴 함
그런데 표본이다보니 오차를 가지고 있음
그래서 어떠한 지표를 만들어서 음식 A가 유의하게 평균이 낮은지
판단하려고 함

F value : 차이 / 불확실도
( 그런데 이건 t value랑 같은 형태, 의미이다. )
하지만 보통 2개 이상 그룹간 차이를 보기 때문에 이 불확실도를
`분산` 으로 변형하여 사용함
( 표본 평균간 빼기를 사용할 수 없어서 `분산`을 약간 변형하여 활용
한다고 하는데, 추가적으로 검색해보니 2개 그룹에 대해서
동분산 가정을 하면 같은 값이 나옵니다.
또한 t value ^2 = f - value 입니다.)

( 그룹간 차이 ) / ( 불확실도 )
그룹간 차이 : 각 표본 평균이 퍼진 정도
표준오차 ( 표본 평균들로 부터 구한 표준오차 ) 를 구할 수 있음
분산 = 표준오차^2 * 샘플 수 ( 분산을 표준오차로부터 구할 수 있음 )

불확실도 : 각각의 표본 집단이 가지는 표준편차를 평균내서 구할 수 있음
불확실도 = (1/3) * ( A 그룹 분산 + B그룹 분산 + 대조군 분산 )
```

ANOVA란?

```
3 이상의 그룹으로부터 F value를 계산하고, 기준 f value 를 계산했을때,
F value 가 기준 값보다 크면
최소한 하나의 그룹이 다른 모집단에서 나왔다는 것

기준이 되는 큰 f value의 의미 :
( 충분히 큰 f value 는 f 분포 상에서 결정됨 )
표본집단들이 하나의 모집단에서 나왔다고 가정했을 때
이런 큰 F-value가 나왔을 확률은 매우 낮으므로,
이 표본집단들이 하나의 모집단에서 나왔을 것이라는
가정이 맞을 확률 또한 매우 낮다고 말할 수 있다.
```

Odds, Logit 이란?

```
odds : 실패비율 대비 성공비율 = p / ( 1-p )
그리고
로짓 : log( odds ) = wx + b // 선형회귀의 결과값 입니다.
위 식을 변형하면(역함수) p = 1 / ( 1 + e^( 예측치 ) ) 입니다.

[0,1] 범위인 확률을 [−∞,∞] 범위로 넓히는 로짓의 특성때문에, 딥러닝에서는 확률화되지 않은 날 예측 결과를 로짓이라고 부릅니다.

===

Q : 시그모이드 함수를 거친 값을 확률로 볼 수 있는가?
A : Logistic(또는 softmax) function은 어떤 값들을 (0, 1) 사이의 값으로 squash하면서,
동시에 값들의 총 합이 1이 되도록 하는 성질이 있는데,
이 결과 logistic function의 함수값이 Kolmogorov의 확률의 정의에 부합하기 때문에
주로 값들을 확률화하는 함수로 쓰인다.
```

공분산과 상관계수란?

```
확률변수가 2가지일때 이 확률분포들이 어떤모양으로 되어있는지를 알고싶을때
가장 먼저 X의 평균, 다음이 Y의 평균이다.

이렇게 되면 대충 분포가 어디에 주로 모여있는지 (m_x, m_y)가 나온다.
그다음으로 궁금한게 얼마나 퍼져있는지 인데 그것은 확률변수의 분산을 구하면 되지만
각 확률변수들이 어떻게 퍼져있는지를 나타내는 것이 공분산(Covariance)이다.

어떻게 퍼져 있는지를 표현한 식이 공분산

그런데 공분산의 문제점이 존재한다.
X와 Y의 단위의 크기에 영향을 받는다는 것이다.
이것을 보완하기 위해 상관계수(Correlation)가 나타난다.
```

회귀분석의 결과 해석

- 모델의 유의성 & 설명력

```
유의성 : p-value
데이터 샘플수(n)가 287개이고
변수의 개수(k)가 2개라면
자유도는 n-k-1 = 284 이다.
이때, 자유도 284 의 F분포에서
F value 값이 상위 5% 내외에 있냐로 유의하다/유의하지 않다를 판단한다.
만약 p-value가 0.05 미만의 아주 작은 값이라면
상위 p-value*100% 의 아주 드문 확률로 우연히 해당 값이 나온다는 뜻인데,
이정도면 유의하게 차이가 난다는 뜻이다.

설명력 : R^2
( SSE / SST , 설명가능한 변동/ 총변동 )
```

- 잔차의 정규성

```
QQ plot 의 대각선상에 잔차들이 가깝게 표시됨
엄밀한 증명 : shapiro test
잔차들의 분포의 정규성을 왜 확인하는가?
각 변수 특정 값에서 잔차가 정규 분포를 띄는지 보고 싶은데
변수 특정 값인 데이터 개수가 너무 적으면 정규성을 띄는지 확인이 불가하여
대안으로 모든 잔차의 정규성을 확인한다.
```

- 잔차의 독립성, 등분산성

```
예측치(x축)로부터 잔차가 x축 값에 상관없이 분포되어 있고
수평선에서 크게 벗어나지 않는지 확인한다.
독립성의 엄밀한 증명 : Durbin-Watson test
```

BootStrap 이란?

```
부트스트랩을 하는 이유 :
샘플에서 얻은 결과(point)를 분포에 대한 가정 없이
신뢰할 수 있는 구간(interval)으로 표현하기 위한 방법론이다.
(ex. 정상적인 게임 유저들의 A 값은 14 이다.
=> 정상적인 게임 유저들의 A 값은 95% 확률로 12 와 16 사이에 있다.)

방법 : 복원추출을 통해 n개의 샘플을 m번 추출하여 평균(통계치)을 내는 것이다.
장점 :
간단하고(반복적인 복원추출 후, 상/하위 n%를 구한다)
분포에 대한 가정이 필요없다. ( CLT 에 의해 샘플에 대한 분포는 정규 분포에 수렴한다. )
```

모수적 방법과 비모수적 방법의 차이는?

```
모수적 방법 : 모집단 분포를 정규분포, 지수분포 등 모수를 갖는 함수 형태의 분포로 가정하고 접근하는 방법
( 분포에 대한 가정이 들어가서, 문제 해결이 더 수월할 수 있으나,
적용 불가능한 상황이 있다. )

비모수적 방법 : 정규분포를 따르지 않거나 표본의 수가 적어서
정규분포를 가정할 수 없는 경우에 부호(+,-)나 순위등에 기초하여 접근하는 방법
```

비모수적 방법의 예시

```
부호검정 : 분포의 중앙값에 대하여 검정. ( 중앙값보다 크면 +. 작으면 - )
귀무가설 : Mu = Mu0
부호간 개수 차이가 크면 귀무가설 기각, 비슷하면 귀무가설 채택

순위검정 : 모수가 적으며, 정규 분포를 따르지 않을 때, 검증 방법으로 치료제 투약이 효과가 있는 지 검정
귀무가설 : 윌콕슨 부호,순위 검정에서의 귀무가설은 중위값이 0이다.
	H0:Δ=0 v.s. H1:Δ≠0
 [2] 두 그룹간 차이 구하기
 [3] 순위 절대값이 - 인 Group ,+ 인 Group을 따로 분리 ( 초록색, 빨간색 )
초록색 합 : 71
빨간색 합 : 7
7,71 가운데 작은 값인 7이 기준
양측검정 T-test 에서 13 미만의
값이 나왔으므로 (좌측 표)
A,B 그룹은 유의미한 차이가
있다고 판단한다.
```