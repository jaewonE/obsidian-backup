독립변수의 개수가 증가하면 일방적으로 값이 증가하는 [[결정계수(R2)]]와 달리 조정된 결정계수는 **독립변수가 증가할 때 분자를 감소시켜주는 연산을 통해 일방적인 증가를 방지한다.** 즉, 설명변수가 많아질수록 패널티를 부여하여 모형이 복잡해지는 것을 방지한다.
$$Adjusted\,\,R^2 = 1-\bigg(\,\,\cfrac{n-1}{n-k-1} \times \cfrac{SSE}{SST} \,\bigg)$$
n은 데이터의 개수이고 k는 설명변수의 개수이다.

-  중다 회귀에서 두 모형의 파라미터 수가 차이 나는 경우에는 조정된 결정 계수를 보고 모형의 정확도와 효율성을 판단하는 것이 중요하다.
-  여러 개의 변수를 사용한 경우에는 두 모형을 비교하기 위해 조정된 결정 계수를 사용해야 한다.
-  일반적인 결정계수보다 작거나 같은 값을 가지며, 모형에 적합하지 않은 변수가 추가되면 감소할 수 있다. (모형에 유용한 변수만을 선택하고 평가하는데 도움을 주어, 과적합을 방지한다.)