>본 문제는 ISLR 라이브러리의 Weekly 자료를 사용한다.

##### 자료 소개
Weekly 자료는 Smarket 자료와 유사히 1990년에서 2010년까지 21년 동안 1089개의 주간 수익률을 포함한다.
코드:
``` R
library(ISLR)
attach(Weekly)

names(Weekly)
View(Weekly)
```

출력:
``` R
> names(Weekly)
[1] "Year"      "Lag1"      "Lag2"      "Lag3"      "Lag4"      "Lag5"      "Volume"   
[8] "Today"     "Direction"

> dim(Weekly)
[1] 1089    9
```

테이블: 
![[4-10 Weekly view sample.png]]
<br>

##### (a). Weekly 자료에 대한 수치 및 그래프적 요약정보를 나타내어라. 어떤 패턴이 있어 보이는가?

###### 1. 서머리 출력
서머리를 출력하여 자료가 어떻게 구성되어 있는지 알아본다.
``` R
summary(Weekly)
```

출력:
``` R
      Year           Lag1               Lag2         
 Min.   :1990   Min.   :-18.1950   Min.   :-18.1950  
 1st Qu.:1995   1st Qu.: -1.1540   1st Qu.: -1.1540  
 Median :2000   Median :  0.2410   Median :  0.2410  
 Mean   :2000   Mean   :  0.1506   Mean   :  0.1511  
 3rd Qu.:2005   3rd Qu.:  1.4050   3rd Qu.:  1.4090  
 Max.   :2010   Max.   : 12.0260   Max.   : 12.0260  
 
      Lag3               Lag4               Lag5         
 Min.   :-18.1950   Min.   :-18.1950   Min.   :-18.1950  
 1st Qu.: -1.1580   1st Qu.: -1.1580   1st Qu.: -1.1660  
 Median :  0.2410   Median :  0.2380   Median :  0.2340  
 Mean   :  0.1472   Mean   :  0.1458   Mean   :  0.1399  
 3rd Qu.:  1.4090   3rd Qu.:  1.4090   3rd Qu.:  1.4050  
 Max.   : 12.0260   Max.   : 12.0260   Max.   : 12.0260  
 
     Volume            Today          Direction 
 Min.   :0.08747   Min.   :-18.1950   Down:484  
 1st Qu.:0.33202   1st Qu.: -1.1540   Up  :605  
 Median :1.00268   Median :  0.2410             
 Mean   :1.57462   Mean   :  0.1499             
 3rd Qu.:2.05373   3rd Qu.:  1.4050             
 Max.   :9.32821   Max.   : 12.0260   
```
<br>

###### 2. 설명변수간의 상관관계를 알아본다.
cor 명령어를 통해서 각 설명변수간의 상관관계를 알아본다. 이때 Direction은 질적변수임으로 cor 설명변수 집합에서 제외하여야 한다. 9번째 자료이기 때문에 `[, -9]` 와 같이 작성하여 Direction 자료를 제외해도 되며 subset 함수를 통해 자료에서 Direction 만 제외할 수도 있다.
``` R
cor(Weekly[, -9])
# cor(subset(Weekly, select = -Direction))
```

출력:
``` R
              Year         Lag1        Lag2        Lag3
Year    1.00000000 -0.032289274 -0.03339001 -0.03000649
Lag1   -0.03228927  1.000000000 -0.07485305  0.05863568
Lag2   -0.03339001 -0.074853051  1.00000000 -0.07572091
Lag3   -0.03000649  0.058635682 -0.07572091  1.00000000
Lag4   -0.03112792 -0.071273876  0.05838153 -0.07539587
Lag5   -0.03051910 -0.008183096 -0.07249948  0.06065717
Volume  0.84194162 -0.064951313 -0.08551314 -0.06928771
Today  -0.03245989 -0.075031842  0.05916672 -0.07124364
               Lag4         Lag5      Volume        Today
Year   -0.031127923 -0.030519101  0.84194162 -0.032459894
Lag1   -0.071273876 -0.008183096 -0.06495131 -0.075031842
Lag2    0.058381535 -0.072499482 -0.08551314  0.059166717
Lag3   -0.075395865  0.060657175 -0.06928771 -0.071243639
Lag4    1.000000000 -0.075675027 -0.06107462 -0.007825873
Lag5   -0.075675027  1.000000000 -0.05851741  0.011012698
Volume -0.061074617 -0.058517414  1.00000000 -0.033077783
Today  -0.007825873  0.011012698 -0.03307778  1.000000000
```
Year과 Volume의 상관계수가 큰것을 확인할 수 있다. 이를 통해 Year과 Volume은 상관관계가 있음을 알 수 있다. 두 상관계수의 값이 양수(0.84194162)인 것을 통해 양의 상관관계를 가짐을 확인 할 수 있다.
<br>

###### 3. pairs 그래프 출력
pairs 그래프를 통해 각 설명변수간의 상관관계를 그래프를 통해 확인한다.
![[4-10-a-3 weekly pairs graph.png]]

Year과 Volume 그래프가 일정한 패턴을 보이는 것을 통해 상관관계가 있음을 확인할 수 있다.
또한 Year과 Volume이 양의 상관관계를 가짐을 확인 할 수 있다. 
<br>
##### (b). 전체 자료를 사용하여 Direction을 반응변수로, 5개의 Lag 변수와 Volume을 설명변수로 하는 로지스틱 회귀를 수행하여라. summary() 함수를 사용하여 결과를 출력하여라. 설명변수 중에서 통계적으로 유의한 것이 있는가? 만약 그렇다면 어느 것인가?
``` R
glm.fit = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, binomial)
summary(glm.fit)
```

출력:
``` R
Call:
glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + 
    Volume, family = binomial)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.6949  -1.2565   0.9913   1.0849   1.4579  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept)  0.26686    0.08593   3.106   0.0019 **
Lag1        -0.04127    0.02641  -1.563   0.1181   
Lag2         0.05844    0.02686   2.175   0.0296 * 
Lag3        -0.01606    0.02666  -0.602   0.5469   
Lag4        -0.02779    0.02646  -1.050   0.2937   
Lag5        -0.01447    0.02638  -0.549   0.5833   
Volume      -0.02274    0.03690  -0.616   0.5377   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1496.2  on 1088  degrees of freedom
Residual deviance: 1486.4  on 1082  degrees of freedom
AIC: 1500.4

Number of Fisher Scoring iterations: 4
```
p값을 통해 Direction과 유의미한 상관관계를 가지는 설명변수는 Lag2 밖에 없음을 확인할 수 있다.
<br>
##### (c). 혼동행렬과 예측이 올바른 전체 비율을 계산하여라. 로지스틱 회귀에 의한 실수 유형에 대해 혼돈행렬로 무엇을 알 수 있는지 설명하여라.
``` R
glm.probs = predict(glm.fit, type="response")
glm.pred = rep("Down", length(Direction))
glm.pred[glm.probs > .5]  = "Up"
table(glm.pred, Direction)
```

출력:
``` R
         Direction
glm.pred Down  Up
    Down   54  48
    Up    430 557
```
민감도는 56.1% 이고 특이도는 43.89%이다. 즉 본 모델은 56.1%로 맞게 예측하였다. 
<br>
##### (d). 1990년에서 2008년까지의 훈련 데이터에 Lag2만 설명변수로 사용하여 로지스틱 회귀모델을 적합하여라. 나머지 데이터(2009년에서 2010년까지의 데이터)에 대해 혼동행렬과 예측이 올바른 전체 비율을 계산하여라.

문제 d에 적합한 전체 코드는 아래와 같다.
``` R
library(ISLR)
attach(Weekly)

train = (Year < 2009)
Weekly.validate = Weekly[!train,]
Direction.validate = Direction[!train]

glm.fit = glm(Direction ~ Lag2, binomial, subset=train)

glm.probs = predict(glm.fit, Weekly.validate, type="response")
glm.pred = rep("Down", length(Direction.validate))
glm.pred[glm.probs > .5]  = "Up"

table(glm.pred, Direction.validate)
```

출력:
``` R
         Direction.validate
glm.pred Down Up
    Down    9  5
    Up     34 56
```
민감도는 62.5% 이고 특이도는 37.5%이다. 즉 본 모델은 62.5%로 맞게 예측하였다. 
<br>
##### (e). LDA를 사용하여 (d)를 반복하라.

LDA를 사용하여 만든 모델의 전체 코드는 아래와 같다.
``` R
library(ISLR)
library(MASS)
attach(Weekly)

train = (Year < 2009)
Weekly.validate = Weekly[!train,]
Direction.validate = Direction[!train]

lda.fit = lda(Direction~Lag2, subset=train)

lda.class = predict(lda.fit, Weekly.validate)$class
table(lda.class, Direction.validate)
```

출력:
``` R
          Direction.validate
lda.class Down Up
     Down    9  5
     Up     34 56
```
민감도는 62.5% 이고 특이도는 37.5%이다. 즉 본 모델은 62.5%로 맞게 예측하였다. 
<br>

###### (f). QDA를 사용하여 (d)를 반복하여라.

QDA를 사용하여 만든 모델의 전체 코드는 아래와 같다.
``` R
library(ISLR)
library(MASS)
attach(Weekly)

train = (Year < 2009)
Weekly.validate = Weekly[!train,]
Direction.validate = Direction[!train]

qda.fit = qda(Direction~Lag2, subset=train)

qda.class = predict(qda.fit, Weekly.validate)$class
table(qda.class, Direction.validate)
```

출력:
``` R
          Direction.validate
qda.class Down Up
     Down    0  0
     Up     43 61
```
민감도는 58.65% 이고 특이도는 41.34%이다. 즉 본 모델은 58.65%로 맞게 예측하였다. 
<br>

##### (g). K = 1 인 KNN을 사용하여 (d)를 반복하여라.

>`as.matrix()` 함수를 통해 데이터프레임을 행렬로 변환할 수 있다.

KNN을 사용하여 만든 모델의 전체 코드는 아래와 같다.
``` R
library(ISLR)
library(class)
attach(Weekly)

train = (Year < 2009)

train.X = as.matrix(Lag2[train])
test.X = as.matrix(Lag2[!train])

train.Y = Direction[train]
test.Y = Direction[!train]

set.seed(1)
knn.pred = knn(train.X, test.X, train.Y, k=1)

table(knn.pred, test.Y)
```

출력:
``` R
         test.Y
knn.pred Down Up
    Down   21 30
    Up     22 31
```
민감도는 50% 이고 특이도는 50%이다. 즉 본 모델은 50%로 맞게 예측하였다. 
<br>
##### (h). 어느 방법이 이 자료에 대해 가장 나은 결과를 제공하는가?

로지스틱 회귀는 56.1%, LDA는 62.5%, QDA는 58.65%, KNN은 50%로 LDA가 가장 나은 결과를 제공한다. 
