## 객체 구성

ISLR 라이브러리에 포함된 Smarket 자료를 이용할 것이다. 이 자료는 2001년에서 2005년까지 1250일에 걸친 S&R 500주가지수의 수익률로 구성되며 각 날짜에 그날 이전 5일의 각 거래일 Lag1에서 Lag5에 대한 수익률이 기록되어 있다.
* Year: 측정 연도
* Lag1, Lag2, ..., Lag5 : 각 날짜에 그날 이전 5일의 각 거래일 Lag1에서 Lag5에 대한 수익률
* Volume: 전날에 거래된 주식 수를 10억 단위로 표시
* Today: 당일의 수익률
* Direction: 당일 주가 지수(질적변수로 Up과 Down으로 구성) 

## 기본 설정
ISLR 라이브러리에 포함된 Smarket 자료를 사용할 것이기에 아래 코드를 추가하여 데이터를 불러올 것이다.
`View 명령어`를 통해 데이터를 표 형식으로 볼 수 있다.
``` R
library(ISLR)
attach(Smarket)
View(Smarket)
```

출력:
![[Smarket_view.png]]


## 로지스틱 회귀
>Lag1, ..., Lag5와 Volume을 이용하여 Direction을 예측하는 로지스틱 회귀모델을 생성한다.

로지스틱 회귀 모델은 일반화선형모델에 적합하는 함수인`gim()` 함수에 `family=binomial` 옵션을 넣어주어 생성할 수 있다. 이에 모델을 생성하고 서머리를 출력하자.
``` R
glm.fit = glm(Direction~Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data=Smarket, family=binomial)
summary(glm.fit)
```

출력: 
``` R
Call:
glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + 
    Volume, family = binomial, data = Smarket)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.446  -1.203   1.065   1.145   1.326  

Coefficients:
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.126000   0.240736  -0.523    0.601
Lag1        -0.073074   0.050167  -1.457    0.145
Lag2        -0.042301   0.050086  -0.845    0.398
Lag3         0.011085   0.049939   0.222    0.824
Lag4         0.009359   0.049974   0.187    0.851
Lag5         0.010313   0.049511   0.208    0.835
Volume       0.135441   0.158360   0.855    0.392

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1731.2  on 1249  degrees of freedom
Residual deviance: 1727.6  on 1243  degrees of freedom
AIC: 1741.6

Number of Fisher Scoring iterations: 3
```
>$Pr(>|z|)$는 정규분포의 절댓값이 z값의 범위를 벗어날 확률이다. 예를 들어 Lag1의 양측검정의 경우 -1.457 보다 작거나 1.457 보다 클 확률이 14.5%라는 것이다. 

<br>
predict() 함수를 사용하면 설명변수 값에 대해 주가지수가 상승할 확률을 예측할 수 있다. 이때 `type="response"` 옵션을 넣어주면 $P(Y=1|X)$ 형태의 확률(X가 $Y=1$(상승) 범위에 속해있을 확률)로 출력한다.

> 주가지수가 상승할 확률인 이유는 Direction에서 상승(Up)이 1로, 하락(Down)이 0으로 인코딩 되었기 때문이다. `contrasts(Direction)` 을 통해 확인할 수 있다. 

``` R
glm.probs = predict(glm.fit, type="response")
print(glm.probs)
```

출력:
![[glm-probs-logi.png]]

출력해보면 1250개의 값에 대한 상승할 확률이 나옴을 알 수 있다.(`dim(Smarket`)) 명령어를 통해서 알 수 있듯 본 데이터는 9개의 열과 1250개의 행(1250개의 데이터)를 가지고 있다.)
<br>
이제 예측한 값과 실제값(Direction)을 혼돈행렬을 통해 비교해보자.
``` R
# "Down" 이라는 원소를 1250개 가지는 벡터를 생성
glm.pred=rep("Down", 1250)

# 만약 glm.probs의 상승확률이 0.5보다 크면 glm.pred 벡터의 "Down" 원소를 "Up"으로 변경한다.
# glm.pred는 "Down"과 "Up"으로만 이루어진 예측값 벡터인 것이다.
glm.pred[glm.probs > .5] = "Up"

# 예측값(glm.pred) 벡터와 실제 결과(Direction)를 혼돈행렬을 통해 비교한다.
table(glm.pred, Direction)
```

출력:
``` R
        Direction
glm.pred Down  Up
    Down  145 141
    Up    457 507
```

이를 통해 민감도는 (507 + 145) / 1250 = 52.16% 이고 특이도는 (457 + 141) / 1250 = 47.84% 임을 확인 할 수 있다. 즉, 이 예에서 로지스틱 회귀는 주가지수의 움직임 방향을 52.16% 올바르게 예측하였다. 

>민감도: 실제로 참이면서 참으로 예측한 비율
>특이도: 실제로 거짓이면서 거짓으로 예측한 비율

>민감도는 각 원소가 일치할 확률의 평균과 같음으로 `mean(glm.pred == Direction)` 함수를 통해 구할 수 있다. 동일한 이유로 특이도는 `mean(glm.pred != Direction)` 함수를 통해 구할 수 있다. 

---
로지스틱 회귀는 52.16% 맞게 예측하였고 47.84% 틀리게 예측하니 무작위 추출(50%) 확률보다 긍정적으로 평가할 수 있다. 하지만 위 47.84%는 훈련오차율로 새로운 데이터를 이용한 검정오차율은 이보다 높을 가능성이 높다. 그러니 마냥 긍정적으로만 볼 수는 없다. 
<br>
>위에서 사용하였던 ISLR 라이브러리의 Smarket 데이터를 사용할 것이다.

위 자료는 2001년부터 2005년 간의 데이터를 가지고 있음으로 2001년부터 2004년까지의 데이터는 훈련데이터로, 2005년 데이터는 검증데이터로 사용하여 검정오차율을 알아보고자 한다. 

먼저 검증에 사용할 2005년 데이터를 추출해주자.
``` R
library(ISLR)
attach(Smarket)

# Year 데이터가 2005보다 작으면 TRUE 그렇지 않으면 FALSE인 원소 1250의 벡터
train = (Year < 2005)

# Smarket의 2005년 이전의 데이터를 Smarket.2005 객체에 저장한다.
# Smarket[!train,]은 Smarket 데이터에서 대응되는 train의 값이 FALSE일 때만 가져온다.(train에 !가 있기에 FALSE일 때 가져옴.)
Smarket.2005 = Smarket[!train,]

# View 명령어를 통해 객체를 표를 통해 확인해보면 모두 Year가 2005인 것을 확인할 수 있다.
# View(train.2005)

#Direction에 대해서도 2005년 자료를 분리해주자.
Direction.2005 = Direction[!train]
```


다음 2001년부터 2004년 사이의 관측치셋만 사용하여 로지스틱 회귀모델을 적합한다.
``` R
# subset 옵션을 통해 제외할 값의 범위를 설정한다. train 벡터의 TRUE 원소에 대응되는 값만 가져온다.
glm.fit = glm(Direction~Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data=Smarket, family=binomial, subset=train)
```

(2001년부터 2004년 사이의 관측치셋을 통해) 학습된 모델을 2005년 관측치셋에 대해서 검증한다. 즉, 2005년 이전의 각 날짜에 대해 주가지수가 상승할 예측확률을 얻는다. 
``` R
# glm.git 모델을 Smarket.2005 검증 데이터를 통해 검증한다.
glm.probs=predict(glm.fit, Smarket.2005, type="response")
```

이제 예측한 값과 실제값(Direction)을 혼돈행렬을 통해 비교해보자.
``` R
# 252개의 "Down" 원소를 가지는 객체를 생성
glm.pred=rep("Down", 252)

# 만약 glm.probs의 상승확률이 0.5보다 크면 glm.pred 벡터의 "Down" 원소를 "Up"으로 변경한다.
# glm.pred는 "Down"과 "Up"으로만 이루어진 예측값 벡터인 것이다.
glm.pred[glm.probs > 0.5] = "Up"

# 예측값(glm.pred) 벡터와 실제 결과(Direction.2005)를 혼돈행렬을 통해 비교한다.
table(glm.pred, Direction.2005)
```

출력: 
``` R
         Direction.2005
glm.pred Down Up
    Down   77 97
    Up     34 44
```

이를 통해 민감도는 (77 + 44) / 252 = 48.01% 이고 특이도는 (34 + 97) / 252 = 51.98% 임을 확인 할 수 있다. 즉, 이 예에서 로지스틱 회귀는 주가지수의 움직임 방향을 48.01% 올바르게 예측하였고 검정오차율은 51.98%인 것이다.

훈련오차율은 약 48%였는 반면 검정오차율은 52%라는 실망스러운 결과이다. 하지만 예견된 결과이다. $Lag_1, .., Lag_5$의 p값은 전반적으로 큰 값을 가졌으니 큰 상관관계가 없었던 것이다. 

이를 통해 반응변수와 상관관계가 없는 설명변수들은 대응하는 편향 감소 없이 분산을 증가시켜, 검정오차율을 악화시키는 경향이 있기에 이러한 설명변수들을 제외하는 것이 모델 개선을 이끌 수 있음을 확인 할 수 있다. 
실제로 p값이 그나마 작은 $Lag_1$과 $Lag_2$만을 설명변수로 사용했을 때, 56%의 확률로 예측에 성공하는 것을 확인할 수 있다.


## 선형판별분석(LDA)
선형판별분석은 MASS 라이브러리의 `lda()` 함수를 사용해 만들 수 있다. `lda()` 함수의 사용 문법은 `lm()`과 동일하다. 예시로 사용되는 데이터는 위와 동일하게 Smarket을 사용한다. 

``` R
library(ISLR)
library(MASS)
attach(Smarket)

# 로지스틱 회귀에서 했듯이 훈련데이터와 검정데이터를 분리한다.
train = (Year < 2005)
Smarket.2005 = Smarket[!train,]
Direction.2005 = Direction[!train]

# lda 함수를 이용하여 선형판별분석 모델을 생성한다. 
lda.fit=lda(Direction~Lag1 + Lag2, data=Smarket, subset=train)
lda.fit

```

``` R
Call:
lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)

Prior probabilities of groups:
    Down       Up 
0.491984 0.508016 

Group means:
            Lag1        Lag2
Down  0.04279022  0.03389409
Up   -0.03954635 -0.03132544

Coefficients of linear discriminants:
            LD1
Lag1 -0.6420190
Lag2 -0.5135293
```

1. "Prior probabilities of groups" 훈련관측치들이 각 범주에 속할 확률이다. 즉, Down Up 각각 0.49와 0.5로 산정됨을 알 수 있다. 
2. "Group mean" 은 집단 별 독립변수 X의 평균을 의미한다. 
	1. 각 클래스 내 각 설명변수의 평균이며 LDA는 이것을 $\mu_k$의 추정치로 사용한다. 
	2. Lag1은 측정 하루 전날이고 Lag2는 측정 이틀 전날임으로 그룹 평균들은
		1. 주가지수가 상승한 날(Up)인 경우 이전 이틀의 수익률은 음수인 경향이 있다.
		2. 주가지수가 하락한 날(Down)인 경우 이전 이틀의 수익률은 양수인 경향이 있다.
3. "Coefficients of linear discriminants" 는 LDA식( $\delta_k(x)=x^T \boldsymbol{\Sigma}^{-1} \mu_k-\frac{1}{2} \mu_k^T \boldsymbol{\Sigma}^{-1} \mu_k+\log \pi_k$ )의 $X=x$에 곱해지는 승수(multiplier)들이다.
	1. $-0.642 \times Lag_1 -0.513 \times Lag_2$가 크면 LDA는 Up을 예측할 것이고 작으면 Down을 예측할 것이다.
	2. `plot(lda.fit)` 함수는 $-0.642 \times Lag_1 -0.513 \times Lag_2$를 계산하여 얻은 선형판별 그래프(히스토그램)를 제공한다.
		![[lda_plot_hist.png]]
		#질문 왜 $-0.642 \times Lag_1 -0.513 \times Lag_2$에 따라 LDA 예측값이 변경되는지 모르겠음. 이 식과 LDA의 판별함수($\delta_k(x)=x^T \boldsymbol{\Sigma}^{-1} \mu_k-\frac{1}{2} \mu_k^T \boldsymbol{\Sigma}^{-1} \mu_k+\log \pi_k$)가 어떠한 연관성을 지니는지 모르겠음.


모델을 만들었으면 `predict()` 함수를 통해 예측해보자.
``` R
lda.pred = predict(lda.fit, Smarket.2005)
```

`predict()` 함수는 class, posterior, x 로 3개의 객체를 포함하는 리스트를 반환한다.
1. class : 주가지수의 움직임에 대한 LDA의 예측을 포함한다.
2. posterior : 사후확률을 포함하는 행렬로, k번째 열은 대응하는 관측치가 k번째 클래스에 속하는 사후확률이며 이 확률은 설명변수 X에 대한 베이즈 정리로부터 구할 수 있다.
3. x : k번째 데이터가 각 범주에 속할 확률. 예를 들어 1241번째 데이터는 0.49의 확률로 Up이고 0.51의 확률로 Down이다. 


예측한 값과 실제 결과를 혼동행렬을 통해 비교해보자.
``` R
# lda.pred에서 class(예측값) 원소만 가져온다.
lda.class = lda.pred$class

# 예측값(lda.class)과 실제 결과(Direction.2005)를 혼동행렬을 통해 비교한다.
table(lda.class, Direction.2005)
```

출력:
``` R
          Direction.2005
lda.class Down  Up
     Down   35  35
     Up     76 106
```

이를 통해 민감도는 (35 + 106) / 252 = 55.95% 이고 특이도는 (76 + 35) / 252 = 44.04% 임을 확인 할 수 있다. 즉, 이 예에서 LDA는 주가지수의 움직임 방향을 55.95% 올바르게 예측하였고 검정오차율은 44.04% 인 것이다.

## 이차판별분석(QDA)
QDA는 MASS 라이브러리의 `qda()`  함수를 사용한다는 것 이외의 사용방법은 LDA와 다를 것 없다. 아래 예시로 보자.

ISLR 라이브러리의 Smarket 데이터셋에서 데이터를 가져와 2005년 이전 데이터는 훈련데이터로, 2005년 데이터는 검정데이터로 분리하자. 
``` R
# 위와 동일한 내용이다.
library(ISLR)
attach(Smarket)
library(MASS)

train = (Year < 2005)
Smarket.2005 = Smarket[!train,]
Direction.2005 = Direction[!train]
```

`qda()` 함수를 이용하여 모델을 생성한다.
``` R
qda.fit = qda(Direction ~ Lag1 + Lag2, data=Smarket, subset=train)
qda.fit
```

출력:
``` R
Call:
qda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)

Prior probabilities of groups:
    Down       Up 
0.491984 0.508016 

Group means:
            Lag1        Lag2
Down  0.04279022  0.03389409
Up   -0.03954635 -0.03132544
```
출력 내용은 LDA와 동일하다. 다만 QDA는 설명변수들이 1차(선형)이 아닌 2차 함수와 관련되기에 선형판별계수값(Coefficients of linear discriminants)을 포함하고 있지 않는다. 

모델을 생성하였다면 `predict()` 함수를 통해 예측을 수행하자
``` R
# predict의 반환값중 class만 사용하니 class만 가져온다.
qda.class=predict(qda.fit, Smarket.2005)$class

# 예측값과 정답을 혼동행렬을 통해 보자.
table(qda.class, Direction.2005)
```

출력:
``` R
          Direction.2005
qda.class Down  Up
     Down   30  20
     Up     81 121
```

이를 통해 민감도는 (30 + 121) / 252 = 59.92% 이고 특이도는 (81+20) / 252 = 40.07% 임을 확인 할 수 있다. 즉, 이 예에서 LDA는 주가지수의 움직임 방향을 59.92% 올바르게 예측하였고 검정오차율은 40.07% 인 것이다. 
현재까지 QDA의 예측성능이 로지스틱 회귀와 선형판별분석보다 상당히 정확한 것을 확인할 수 있다.


## K-최근접이웃(KNN)
이번에는 위의 Smarket 자료를 비모수적 방법인 KNN을 이용하여 예측해보고 모수적 방법인 로지스틱 회귀, LDA, QDA와 비교해보자.

우선 KNN 모델적합은 위의 모델적합과 다른 방식으로 작동한다. 위에서는 모델을 생성하고 예측하여 성능을 평가하였는 반면 KNN 모델은 모델 생성과 동시에 예측, 성능평가를 한번에 진행한다. 따라서 KNN 모델은 아래 4개의 입력을 동시에 받는다.
1. train.X : 훈련 설명변수 행렬
2. test.X  : 검정 설명변수 행렬
3. train.Direction : 훈련 반응변수로 훈련 관측치들에 대한 클래스 라벨을 포함하는 벡터
4. k : 분류기가 사용할 최근접 이웃의 수를 나타내는 K값

먼저 KNN 모델을 생성하는 `knn()` 함수를 class 라이브러리에서 불러온 뒤 훈련데이터와 검증데이터를 분리해주자.
``` R
library(ISLR)
library(class)
attach(Smarket)

train = (Year < 2005)

# 2005년 이전의 Lag1과 Lag2 데이터를 묶어 train.X 객체에 저장한다.
train.X = cbind(Lag1, Lag2)[train,]

# 2005년 이후의 Lag1과 Lag2 데이터를 묶어 test.X 객체에 저장한다.
test.X = cbind(Lag1, Lag2)[!train,]

# 2005년 이후의 Direction(정답) 벡터를 train.Direction 객체에 저장한다.
train.Direction = Direction[train]

# 2005년 이후의 Direction(정답) 벡터를 Direction.2005 객체에 저장한다.
Direction.2005 = Direction[!train]
```

이제 `knn()` 함수를 이용하여 knn 모델을 생성하자. 
knn 모델은 여러 개의 관측치가 동일하게 가까운 이웃으로 판단될 때 둘 중 하나를 선택해야 한다. 이때 시드값을 통해 둘 중 하나를 판단하게 되고 이는 다음에 동일한 시드값을 넣었을 때 동일하게 둘 중 하나를 판단하게 한다. 시드값은 `set.seed()` 함수를 통해 설정할 수 있다.
``` R
# 시드값을 설정한다.
set.seed(1)

# 모델을 생헝한다.
knn.pred = knn(train.X, test.X, train.Direction, k=1)

# 모델의 예측값과 실제 정답을 혼동행렬을 통해 비교한다. 
table(knn.pred, Direction.2005)
```

출력:
``` R
         Direction.2005
knn.pred Down Up
    Down   43 58
    Up     68 83
```

이를 통해 민감도는 (30 + 121) / 252 = 59.92% 이고 특이도는 (81+20) / 252 = 40.07% 임을 확인 할 수 있다. 즉, 이 예에서 LDA는 주가지수의 움직임 방향을 59.92% 올바르게 예측하였고 검정오차율은 40.07% 인 것이다. 