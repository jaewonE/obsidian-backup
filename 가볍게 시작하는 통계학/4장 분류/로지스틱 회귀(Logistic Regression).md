로지스틱 회귀(Logistic Regression)는 반응변수 Y를 직접 모델링하지 않고 Y가 특정 범주에 속하는 확률을 모델링 한다. 

### 선형회귀모델의 한계
![[선형회귀의 한계]]


### 로지스틱 회귀
위와 같은 [[선형회귀의 한계]]를 극복하고자 탄생한 것이 로지스틱 회귀 모델이다. 

선형회귀모델의 가장 큰 문제이자 한계점은 **"결과값(반응변수)의 값이 $0<Y<1$의 범위를 만족하지 않는다"** 는 것이다. 이 문제를 해결하기 위해 모든 X 값에 대해 0과 1 사이의 값을 제공하는 [[시그모이드 함수]], 그 중에서도 [[로지스틱함수]]를 이용하여 회귀 모델을 작성하였는데 이것이 바로 **로지스틱 회귀**이다.

![[로지스틱함수#정의]]

![[로지스틱함수#로지스틱 함수의 로짓 변환]]

### 로지스틱 회귀계수의 추정
위의 로짓변환 과정을 통해 로지스틱 함수를 $log(Odds)=\beta_0 + \beta_1X$와 같이 간단한 선형 함수로 재구성하였다. 이에 [[최대 우도 추정법(MLE)]]을 이용하여 관측값을 통해 모수의 추정치를 도출 할 수 있다. 이 과정을 로지스틱 회귀계수의 추정이라고 부른다. 

### 로지스틱 회귀계수 추정의 해석
로지스틱 회귀계수의 추정 과정을 통해 다음과 같은 결과를 얻었다고 가정하자. 
> 사용된 로지스틱 회귀함수의 형태는 $p(y=1|x) = {\frac {e^{\beta \centerdot X_{i}}}{1+e^{\beta \centerdot X_{i}}}}$와 같고 