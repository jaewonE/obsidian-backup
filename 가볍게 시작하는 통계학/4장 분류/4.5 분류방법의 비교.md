이 장에서는 [[로지스틱 회귀(Logistic Regression)]], [[선형판별분석(LDA)]], [[이차선형판별분석(QDA)]], [[KNN K-최근접이웃]] 방법의 특징점을 비교하고 어느 한 기법이 다른 기법보다 우세한 상황을 고려해보자.


## 로지스틱 회귀 vs LDA

### 공통점과 차이점

로지스틱 회귀는 [[로짓(odds ratio) 과 로짓변환(Logit transformation)|로짓변환]]을 통해 
$$log\bigg(\cfrac{p_1}{1-p_1}\bigg) = \beta_0 + \beta_1x$$
로 표현될 수 있고 LDA 또한 로짓변환을 통해
$$log\bigg(\cfrac{p_1(x)}{1-p_1(x)}\bigg) = log\bigg(\cfrac{p_1(x)}{p_2(x)}\bigg) = c_0 + c_1x$$
로 표현될 수 있다. 

로지스틱 회귀와 LDA 모두 로짓변환된 식은 x의 선형함수이다. 즉, 로지스틱 회귀와 LDA 모두 선형의 결정경계를 만든다는 공통점이 있다.

두 기법 사이의 유일한 차이점은 추정 방법이다. 로지스틱 회귀의 회귀계수($\beta_0\,,\,\beta_1$)는 최대가능도를 사용하여 추정되는 반면 LDA의 계수($c_0\,,\,c_1$)는 정규분포로부터 추정된 평균과 분산을 사용하여 계산된다. 


### 상황에 따른 적합한 모델
LDA는 관측치들이 각 클래스에 공통인 공분산행렬을 갖는 가우스분포를 따른다고 가정한다.
이 가정이 근사적으로 성립할 때 LDA는 로지스틱 회귀보다 더 좋은 성능을 낸다.
하지만 가우스 가정이 만족되지 않으면 로지스틱 회귀가 LDA보다 더 좋은 성능을 낸다.


## KNN vs LDA, 로지스틱회귀
KNN은 완전히 비모수적인 방법이다. 즉, 결정경계의 형태에 대해 어떠한 가정도 하지 않는다. 
이에 결정경계가 상당히 비선형적인 경우 KNN이 LDA와 로지스틱회귀보다 더 좋은 성능을 낼 것이다.
하지만 KNN은 어느 설명변수가 중요한지 알 수 없어 회귀계수를 얻지 못한다.


## QDA는 KNN와 LDA의 절충이다.
QDA는 비모수적 방법인 KNN과 선형의 LDA 또는 로지스틱 회귀가 절충된 기법을 KNN 만큼 유연하지는 않지만 결정경계의 형태에 대해 몇 가지 가정을 하기 때문에 훈련 관측치의 수가 제한적인 경우에 KNN보다 더 좋은 성능을 낼 수도 있다.



